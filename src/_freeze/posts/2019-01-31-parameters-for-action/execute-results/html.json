{
  "hash": "292aeb89a49a0a37722e99d7ac0bf7a3",
  "result": {
    "markdown": "---\ntitle: Parameters for action\nauthor: \"\"\ndate: '2019-01-31'\ncategories: [science]\n---\n\n\nSeveral years ago, Florian Raudies, Swapnaa Jayaraman and I published a [paper](https://doi.org/10.1109/DEVLRN.2015.7345450) where we simulated the optic flow that infants would experience in different head/body postures.\nWe computed cyclopian (one-eyed) flow on the basis of this schematic:\n\n<img src=\"https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/computing-flow.jpg\"/>\n\nHere, the key parameters were the instantaneous translation $(v_x{}, v_y{}, v_z{})$ and rotation $(\\omega_{x}, \\omega_y{}, \\omega_z{})$ of the planar retina.\nCoupled with the optic flow equation,\n\n$\\begin{pmatrix}\\dot{x} \\\\ \\dot{y}\\end{pmatrix}=\\frac{1}{z} \\begin{pmatrix}-f & 0 & x\\\\ 0 & -f & y \\end{pmatrix} \\begin{pmatrix}{v_x{}}\\\\ {v_y{}} \\\\{v_z{}}\\end{pmatrix}+ \\frac{1}{f} \\begin{pmatrix} xy & -(f^2+x^2) & fy\\\\ f^2+y^2 & -xy & -fy \\end{pmatrix} \\begin{pmatrix} \\omega_{x}\\\\ \\omega_{y}\\\\ \\omega_{z} \\end{pmatrix}$\n\nwe were able to simulate the *perceptual* effects of postural geometry: Changes in eye height and forward translational speed that would occur when a child changed from crawling to walking altered the pattern of retinal flow $(\\dot{x}, \\dot{y})$ in interesting ways.\n\nThis work has lain dormant for a few years, but I now want to pick it back up.\nIn short, there are a handful of perception/action systems that provide the nervous system with deterministic, causal information about the effects of different actions.\nThese must be important for development.\n\nFor the next step, I'm looking for a concise, but thorough parameterization of body posture that includes the eyes, head, torso, arms, and legs.\nHere's a sketch of what I have in mind for the upper parts body that have the greatest impact on the direction of visual fixation:\n\n| Body part | Parameter(s) |\n|-----------|--------------|\n| Eyes      | $\\omega_{rx}, \\omega_{ry}, \\omega_{lx}, \\omega_{lx} $|\n| Head      | $\\theta_x{}, \\theta_y{}, \\theta_z{}$ |\n| Torso     | $\\alpha_x{}, \\alpha_y{}, \\alpha_z{} $ |\n\nCoupled with the distance between the eyes, $i$, the radial distance to the head's center of rotation, $h$, and the distance from the head's center of rotation to the torso's center of rotation, $t$, we can compute the effects of eye, head, and torso movement on visual motion at the two retinae.\nNow, if the *visual* signals from eye vs. head vs. torso can be distinguished, then these could couple with other proprioceptive (muscle, tendon, cutaneous) signals to provide a powerful set of *sensory* signals that are directly caused by eye, head, and torso motion.\nSee [this earlier post](../the-webs-we-weave/) for a causal graph that elaborates on this point.\nI'll discuss why I think there are *visual* differences in the effects of eye and head motion in a future post.\n\nMy next step is to ask my colleagues in kinesiology if there is a canonical parameterization of body position that I can build upon.\nIf you know of one, let me know.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}